{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and SGD Homework \n",
    "***\n",
    "**Name**: $<$**Juan Lin**$>$ \n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5pm on Friday February 9th**. Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc. Your solutions to analysis questions should be done in Markdown directly below the associated question.  Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**.  For a refresher on the course **Collaboration Policy** click [here](https://github.com/chrisketelsen/CSCI5622-Machine-Learning/blob/master/resources/syllabus.md#collaboration-policy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "***\n",
    "\n",
    "\n",
    "In this homework you'll implement stochastic gradient ascent for logistic regression and you'll apply it to the task of determining whether documents are talking about automobiles or motorcycles.\n",
    "\n",
    "<br>\n",
    "\n",
    "![autos_motorcycles](autos_motorcycles.jpg \"A car and a motorcycle\")\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "You should not use any libraries that implement any of the functionality of logistic regression for this assignment; logistic regression is implemented in Scikit-Learn, but you should do everything by hand now. You'll be able to use library implementations of logistic regression in the future.\n",
    "\n",
    "Here are the rules: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. \n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5 points] Problem 1: Loading and Exploring the Data\n",
    "***\n",
    "\n",
    "The `Example` class will be used to store the features and labels associated with a single training or test example.  The `read_data` function will read in the text data and split it into training and test sets.  \n",
    "\n",
    " Load the data and then do the following: \n",
    "- Report the number of words in the vocabulary \n",
    "- Explain how the code is creating features (i.e. what text model is being used). \n",
    "- Go into the raw text files in the data directory and figure out which label (0/1) refers to which class of document (automobiles or motorcycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kSEED = 1735\n",
    "kBIAS = \"BIAS_CONSTANT\"\n",
    "\n",
    "np.random.seed(kSEED)\n",
    "\n",
    "class Example:\n",
    "    \"\"\"\n",
    "    Class to represent a document example\n",
    "    \"\"\"\n",
    "    def __init__(self, label, words, vocab):\n",
    "        \"\"\"\n",
    "        Create a new example\n",
    "\n",
    "        :param label: The label (0 / 1) of the example\n",
    "        :param words: The words in a list of \"word:count\" format\n",
    "        :param vocab: The vocabulary to use as features (list)\n",
    "        \"\"\"\n",
    "        self.nonzero = {}\n",
    "        self.y = label\n",
    "        self.x = np.zeros(len(vocab))\n",
    "        for word, count in [x.split(\":\") for x in words]:\n",
    "            if word in vocab:\n",
    "                assert word != kBIAS, \"Bias can't actually appear in document\"\n",
    "                self.x[vocab.index(word)] += float(count)\n",
    "                self.nonzero[vocab.index(word)] = word\n",
    "        self.x[0] = 1\n",
    "\n",
    "def read_dataset(positive, negative, vocab, train_frac=0.9):\n",
    "    \"\"\"\n",
    "    Reads in a text dataset with a given vocabulary\n",
    "\n",
    "    :param positive: Positive examples\n",
    "    :param negative: Negative examples\n",
    "    :param vocab: A list of vocabulary words\n",
    "    :param test_frac: How much of the data should be reserved for test\n",
    "    \"\"\"\n",
    "\n",
    "    vocab = [x.split(\"\\t\")[0] for x in open(vocab, 'r') if '\\t' in x]\n",
    "    assert vocab[0] == kBIAS, \\\n",
    "        \"First vocab word must be bias term (was %s)\" % vocab[0]\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for label, input in [(1, positive), (0, negative)]:\n",
    "        for line in open(input):\n",
    "            ex = Example(label, line.split(), vocab)\n",
    "            if np.random.random() <= train_frac:\n",
    "                train_set.append(ex)\n",
    "            else:\n",
    "                test_set.append(ex)\n",
    "\n",
    "    # Shuffle the data \n",
    "    np.random.shuffle(train_set)\n",
    "    np.random.shuffle(test_set)\n",
    "\n",
    "    return train_set, test_set, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_fname = \"../data/autos_motorcycles/positive\"\n",
    "neg_fname = \"../data/autos_motorcycles/negative\"\n",
    "voc_fname = \"../data/autos_motorcycles/vocab\"\n",
    "train_set, test_set, vocab = read_dataset(pos_fname, neg_fname, voc_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of words in vocabulary is\", len(vocab)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain how the code is creating features (i.e. what text model is being used).** \n",
    "\n",
    "The code looks through the positive and negavite files and find the words frequency appeared with each sample in each file, created an arrray with the element reflects the word frequency based on the given vocabulary file. In other words, the code is using the Bag-of-Words Text model.\n",
    "\n",
    "** Go into the raw text files in the data directory and figure out which label (0/1) refers to which class of document (automobiles or motorcycles)**\n",
    "\n",
    "label 1 refers to positive, positive raw files refer to motorcycles. label 0 refers to negative, negative raw files refer to automobiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [25 points] Problem 2: Implementing SGD with Lazy Sparse Regularization\n",
    "***\n",
    "\n",
    "We've given you a class `LogReg` below which will train a logistic regression classifier to predict whether a document is talking about automobiles or motorcycles. \n",
    "\n",
    "**Part A**: In this problem you will modify the `sgd_update` function to perform **unregularized** stochastic gradient descent updates of the weights. Note that you should only update the weights for **non-zero** features, i.e. weights associated with words that appear in the current training example. The code below this cell demonstrates how to instantiate the class and train the classifier.   \n",
    "\n",
    "We've also given you unit tests in the next cell based on the simple example worked out in  the Lecture 4 in-class notebook.  At first your code will fail both of them. When your code is working you should pass tests called `test_unreg` and `test_learnrate`.  Do not move on to **Part A** until your code passes both of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogReg:\n",
    "    def __init__(self, train_set, test_set, lam, eta=0.1):\n",
    "        \"\"\"\n",
    "        Create a logistic regression classifier\n",
    "\n",
    "        :param train_set: A set of training examples\n",
    "        :param test_set: A set of test examples \n",
    "        :param lam: Regularization parameter\n",
    "        :param eta: The learning rate to use \n",
    "        \"\"\"\n",
    "        \n",
    "        # Store training and test sets \n",
    "        self.train_set = train_set\n",
    "        self.test_set = test_set \n",
    "        \n",
    "        # Initialize vector of weights to zero  \n",
    "        self.w = np.zeros_like(train_set[0].x)\n",
    "        \n",
    "        # Store regularization parameter and eta function \n",
    "        self.lam = lam\n",
    "        self.eta = eta\n",
    "        \n",
    "        # Create dictionary for lazy-sparse regularization\n",
    "#         self.last_update = dict()\n",
    "        self.last_update = dict((elem, 0) for elem in [i for i in range(1, len(self.w))])\n",
    "        # Make sure regularization parameter is not negative \n",
    "        assert self.lam>= 0, \"Regularization parameter must be non-negative\"\n",
    "        \n",
    "        # Empty lists to store NLL and accuracy on train and test sets \n",
    "        self.train_nll = []\n",
    "        self.test_nll = []\n",
    "        self.train_acc = []\n",
    "        self.test_acc = []\n",
    "        \n",
    "    def sigmoid(self,score, threshold=20.0):\n",
    "        \"\"\"\n",
    "        Prevent overflow of exp by capping activation at 20.\n",
    "        You do not need to change this function. \n",
    "\n",
    "        :param score: A real valued number to convert into a number between 0 and 1\n",
    "        \"\"\"\n",
    "\n",
    "        # if score > threshold, cap value at score \n",
    "        if abs(score) > threshold:\n",
    "            score = threshold * np.sign(score)\n",
    "\n",
    "        return 1.0 / (1.0 + np.exp(-score)) \n",
    "\n",
    "    def compute_progress(self, examples):\n",
    "        \"\"\"\n",
    "        Given a set of examples, compute the NLL and accuracy\n",
    "        You shouldn't need to change this function. \n",
    "\n",
    "        :param examples: The dataset to score\n",
    "        :return: A tuple of (log probability, accuracy)\n",
    "        \"\"\"\n",
    "\n",
    "        NLL = 0.0\n",
    "        num_correct = 0\n",
    "        for ex in examples:\n",
    "            # compute prob prediction\n",
    "            p = self.sigmoid(self.w.dot(ex.x))\n",
    "            # update negative log likelihood\n",
    "            NLL = NLL - np.log(p) if ex.y==1 else NLL - np.log(1.0-p)\n",
    "            # update number correct \n",
    "            num_correct += 1 if np.floor(p+.5)==ex.y else 0\n",
    "\n",
    "        return NLL, float(num_correct) / float(len(examples))\n",
    "    \n",
    "    def train(self, num_epochs=1, isVerbose=False, report_step=5):\n",
    "        \"\"\"\n",
    "        Train the logistic regression classifier on the training data \n",
    "\n",
    "        :param num_epochs: number of full passes over data to perform \n",
    "        :param isVerbose: boolean indicating whether to print progress\n",
    "        :param report_step: how many iterations between recording progress\n",
    "        \"\"\"\n",
    "        iteration = 0\n",
    "        # Perform an epoch \n",
    "        for pp in range(num_epochs):\n",
    "            # shuffle the data  \n",
    "            np.random.shuffle(self.train_set)\n",
    "            # loop over each training example\n",
    "            for ex in self.train_set:\n",
    "                # perform SGD update of weights \n",
    "                self.sgd_update(ex, iteration)\n",
    "                # record progress \n",
    "                if iteration % report_step == 1:\n",
    "                    train_nll, train_acc = self.compute_progress(self.train_set)\n",
    "                    test_nll, test_acc = self.compute_progress(self.test_set)\n",
    "                    self.train_nll.append(train_nll)\n",
    "                    self.test_nll.append(test_nll)\n",
    "                    self.train_acc.append(train_acc)\n",
    "                    self.test_acc.append(test_acc)\n",
    "#                     print(self.test_acc)\n",
    "                    if isVerbose:\n",
    "                        print(\"Update {: 5d}  TrnNLL {: 8.3f}  TstNLL {: 8.3f}  TrnA {:.3f}  TstA {:.3f}\"\n",
    "                             .format(iteration-1, train_nll, test_nll, train_acc, test_acc))\n",
    "                iteration += 1\n",
    "    \n",
    "    def sgd_update(self, train_example, iteration):\n",
    "        \"\"\"\n",
    "        Compute a stochastic gradient update to improve the NLL \n",
    "\n",
    "        :param train_example: The example to take the gradient with respect to\n",
    "        :param iteration: The current iteration (an integer)\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO implement LSR updates of weights \n",
    "        self.w = self.w \n",
    "        x = train_example.x\n",
    "        y = train_example.y\n",
    "\n",
    "        output = self.sigmoid(self.w.dot(x))\n",
    "        \n",
    "        error = output - y\n",
    "        \n",
    "        self.w[0] += - self.eta *(x[0] * (error))\n",
    "        \n",
    "        for i in range(1, len(x)):\n",
    "            \n",
    "            if x[i] != 0 and i != 0:\n",
    "                \n",
    "                \n",
    "                self.w[i] += - self.eta * (x[i] * (error))\n",
    "                   \n",
    "# #   lazy sparse regularization\n",
    "                self.w[i] = self.w[i] * (1 - (2* self.eta * self.lam)) ** (iteration - self.last_update[i] + 1)\n",
    "                self.last_update[i] = iteration + 1\n",
    "              \n",
    "        return self.w\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogReg(train_set, test_set, lam=0, eta=0.1)\n",
    "lr.train(isVerbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unit tests are located in the script `tests.py` in this directory.  Execute the following cell to call the script and run the tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i tests.py \"part A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: After your unregularized updates are working, modify the `sgd_update` function again to perform regularized updates using **Lazy Sparse Regularization**. Note that you should not regularize the bias weight. See the Lecture 4 in-class notebook for a refresher on LSR. **Note**: After implementing LSR, your code should still pass the unit tests for **Part A** when `lam = 0`. \n",
    "\n",
    "We've given you a third unit test in the next cell called `test_reg` based on the simple example of LSR worked out in  the Lecture 4 in-class notebook.  Do not move on to **Problem 3** until your code passes the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i tests.py \"part B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 points] Problem 3: Hyperparameter Tuning \n",
    "***\n",
    "\n",
    "**Part A**: Perform a systematic study of the effect of the regularization parameter on the accuracy of your classifier on the test set.  Which choice of `lam` seems to do the best?  Justify your conclusion with some kind of graphic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part A Answer**: As the lam gets bigger, the accuracy gets worse. Based on the graph below, the lam of 0 seems to do the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_lambda = []\n",
    "for x in range(0,11):\n",
    "    lr = LogReg(train_set, test_set, x/10, eta=0.1)\n",
    "    lr.train()\n",
    "    accuracy_lambda.append(sum(lr.test_acc)/len(lr.test_acc))\n",
    "    lambda_value = [i for i in range(0,11)]\n",
    "fig = plt.figure()\n",
    "plt.axis([0, 11, 0, 1])    \n",
    "plt.plot(lambda_value, accuracy_lambda,'ro')\n",
    "plt.xlabel('lambda value')\n",
    "plt.ylabel('accuracy based on the lambda value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: For the value of `lam` chosen in **Part A** perform a systematic study of the choice of learning rate on the speed of convergence SGD.  Which learning rate seems to give the fastest convergence?  Justify your conclusion with some kind of graphic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B Answer** : Based on the graph below, when the learning rate is 0.03, it reaches the convergence with less few iterations than the others. In general, the smaller the learning rate, the faster convergence you will get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speed_SGD(x):\n",
    "    \n",
    "    lr = LogReg(train_set, test_set, lam=0, eta=x)\n",
    "    lr.train()\n",
    "    lr.test_acc\n",
    "    iteration_value = [i for i in range(0,len(lr.test_acc))]\n",
    "    \n",
    "    plt.axis([0, 220, 0.4, 1])    \n",
    "    plt.plot(iteration_value, lr.test_acc,'ro')\n",
    "    plt.xlabel('iteration value')\n",
    "#     plt.ylabel('accuracy based on the iteration times')\n",
    "    \n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(431); plot_speed_SGD(0.01)\n",
    "plt.subplot(432); plot_speed_SGD(0.02)\n",
    "plt.subplot(433); plot_speed_SGD(0.03)\n",
    "plt.subplot(434); plot_speed_SGD(0.1)\n",
    "plt.subplot(435); plot_speed_SGD(0.3)\n",
    "plt.subplot(436); plot_speed_SGD(0.5)\n",
    "plt.subplot(437); plot_speed_SGD(0.7)\n",
    "plt.subplot(438); plot_speed_SGD(0.9)\n",
    "plt.subplot(439); plot_speed_SGD(1.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 points] Problem 4: Identifying Predictive and Non-Predictive Words \n",
    "***\n",
    "\n",
    "**Part A**: Find the top 10 words that are the best predictors for each class.  Explain mathematically how you identified them and show any code that you used to find them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Part A answer**  \n",
    "\n",
    "The best predictors for label 0 is {'heater', 'importing', 'hitting', 'complaints', 'tall', 'detectors', 'equivalent', 'shocked', 'grovel', 'instances'} and for label 1 is {'existing', 'alternative', 'festival', 'prior', 'cheers', 'slack', 'buyer', 'thief', 'hospitals', 'clamps'}. By sorting the weight in ascending and descending order and get the first top ten words for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_class(word):\n",
    "    \n",
    "    for i in word:\n",
    "        aa.append(vocab[i])\n",
    "        from collections import Counter\n",
    "        cnt = Counter()\n",
    "        for word in aa:\n",
    "            cnt[word] += 1\n",
    "            \n",
    "    print(cnt.most_common(10))\n",
    "\n",
    "iteration = 0\n",
    "aa = []\n",
    "for ex in train_set:\n",
    "    weight = lr.sgd_update(ex, iteration)\n",
    "    word_prediction_label0 = np.argsort(weight)[:10]\n",
    "    best = predictor_class(word_prediction_label0)\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_class(word):\n",
    "    \n",
    "    for i in word:\n",
    "        aa.append(vocab[i])\n",
    "        from collections import Counter\n",
    "        cnt = Counter()\n",
    "        for word in aa:\n",
    "            cnt[word] += 1\n",
    "            \n",
    "    print(cnt.most_common(10))\n",
    "iteration = 0\n",
    "aa = []\n",
    "for ex in train_set:\n",
    "    weight = lr.sgd_update(ex, iteration)\n",
    "    word_prediction_label1 = np.argsort(weight)[-10:]\n",
    "    best = predictor_class(word_prediction_label1)\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Find the 10 words that are the worst predictors for class.  Explain mathematically how you identified them and show any code that you used to find them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part B Answer : ** The worst predictors should be the weights close to zero. So in this case, get the absolute weight value and then the first ten corresponding value from the vocabulary. From the code below, the 10 words are {'crank', 'cochran', 'trash', 'whatsoever', 'girls', 'sakes', 'copied', 'failing', 'hospital', 'spoken'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "aa = []\n",
    "for ex in train_set:\n",
    "    weight = lr.sgd_update(ex, iteration)\n",
    "    word_worst_predictor = np.argsort(abs(weight))[:10]\n",
    "\n",
    "    for i in word_worst_predictor:\n",
    "        aa.append(vocab[i])\n",
    "\n",
    "        from collections import Counter\n",
    "        cnt = Counter()\n",
    "        for word in aa:\n",
    "            cnt[word] += 1\n",
    "    \n",
    "    iteration += 1\n",
    "print(cnt.most_common(10)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
